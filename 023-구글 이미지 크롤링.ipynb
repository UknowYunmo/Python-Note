{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "웹에 있는 사진을 크롤링 하는 방법 ( 구글 이미지 )\n",
    "\n",
    "\n",
    "\n",
    "셀레니움을 써서 마치 손으로 클릭해서 이미지를 저장하듯 저장을 하는데\n",
    "\n",
    "컴퓨터를 시켜서 이 과정을 자동화 시키는 방법으로 스크롤링을 한다.\n",
    "\n",
    "\n",
    "\n",
    "< 구글 이미지 스크롤링 준비 >\n",
    "\n",
    "\n",
    "\n",
    "1. 크롬 웹브라우저가 설치 되어있어야 한다.\n",
    "\n",
    "2. c 드라이브 밑에 chromedriver 폴더를 생성하고, chromedriver.exe를 넣는다.\n",
    "\n",
    "3. c 드라이브 밑에 gimages 폴더를 생성한다.\n",
    "\n",
    "4. 다운 받을 이미지의 키워드를 결정한다.\n",
    "\n",
    "5. 아나콘다 프롬프트 창을 열고 selenium을 설치\n",
    "\n",
    "conda install selenium 또는 pip install selenium 을 입력하면 설치가 진행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밑 코드 쭉 긁어서 바로 사용 가능\n",
    "\n",
    "\n",
    "\n",
    "import urllib.request # 웹 url을 파이썬이 인식 할 수 있게하는 패키지\n",
    "\n",
    "from  bs4 import BeautifulSoup # html에서 데이터 검색을 용이하게 하는 패키지\n",
    "\n",
    "from selenium import webdriver  \n",
    "\n",
    "\n",
    "\n",
    "# selenium : 웹 애플리케이션의 테스트를 자동화하기 위한 프레임 워크 \n",
    "\n",
    "# 손으로 클릭하는것을  컴퓨터가 대신하면서 스크롤링하게 하는 패키지\n",
    "\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import time       # 중간중간 sleep 을 걸어야 해서 time 모듈 import\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################### url 받아오기 ###########################\n",
    "\n",
    "\n",
    "\n",
    "binary = 'C:\\chromedriver\\chromedriver.exe'    # 크롬 드라이버 사용\n",
    "\n",
    "browser = webdriver.Chrome(binary)    # 브라우져를 인스턴스화\n",
    "\n",
    "browser.get(\"https://www.google.co.kr/imghp?hl=ko&tab=wi&ei=l1AdWbegOcra8QXvtr-4Cw&ved=0EKouCBUoAQ\") # 구글의 이미지 검색 url 받아옴(아무것도 안 쳤을때의 url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#검색창에 해당하는 html코드를 찾아서 elem 클래스 부분에 입력 ( 사이트에서 크롬 관리자 모드 사용해서 검색 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# elem = browser.find_elements_by_class_name('gLFyf gsfi') # Tip : f12누른후 커서를 검색창에 올려두고 id를 찾으면 best, id가 없으면 class로\n",
    "\n",
    "elem = browser.find_element_by_xpath(\"//*[@class='gLFyf gsfi']\")  # 위의 코드대로 하거나 이렇게 하거나 둘 중 하나 select\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 검색어 입력 파트\n",
    "\n",
    "\n",
    "\n",
    "elem.send_keys(\"짱구 훈이\") # 여기에 스크롤링하고싶은 검색어를 입력\n",
    "\n",
    "elem.submit() # 웹에서의 submit 은 엔터의 역할을 함\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 반복문\n",
    "\n",
    "\n",
    "\n",
    "# 스크롤을 내리려면 브라우져 이미지 검색결과 부분(바디부분)에 마우스 클릭 한번 하고 End키를 눌러야함\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 6): # 5번 스크롤 내려가게 구현된 상태 range(1,5)\n",
    "\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "\n",
    "    time.sleep(10)          # END 키 누르고 내려가는데 시간이 걸려서 sleep 해줌 / 키보드 end키를 총 5번 누르는데 end 1번누르고 10초 쉼\n",
    "\n",
    "time.sleep(10)                      # 네트워크 느릴까봐 안정성 위해 sleep 해줌(이거 안하면 하얀색 이미지가 다운받아질 수 있음.)\n",
    "\n",
    "html = browser.page_source         # 크롬브라우져에서 현재 불러온 소스 가져옴\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\") # html 코드를 검색할 수 있도록 설정\n",
    "\n",
    "browser.find_element_by_xpath(\"//*[@class='mye4qd']\").click()  # 여기가 결과 더 보기 코드\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 5): # 4번 스크롤 내려가게 구현된 상태 \n",
    "\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "\n",
    "    time.sleep(10)          # END 키 누르고 내려가는데 시간이 걸려서 sleep 해줌 / 키보드 end키를 총 5번 누르는데 end1번누르고 10초 쉼\n",
    "\n",
    "time.sleep(10)                      # 네트워크 느릴까봐 안정성 위해 sleep 해줌(이거 안하면 하얀색 이미지가 다운받아질 수 있음.)\n",
    "\n",
    "html = browser.page_source         # 크롬브라우져에서 현재 불러온 소스 가져옴\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\") # html 코드를 검색할 수 있도록 설정\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 그림 파일 저장\n",
    "\n",
    "\n",
    "\n",
    "### 검색한 구글 이미지의 url을 따오는 코드 ###\n",
    "\n",
    "\n",
    "\n",
    "def fetch_list_url():\n",
    "\n",
    "    params = []\n",
    "\n",
    "    imgList = soup.find_all(\"img\", class_=\"rg_i Q4LuWd\")  # 구글 이미지 url 이 있는 img 태그의 _img 클래스에 가서 (f12로 확인가능.)\n",
    "\n",
    "    for im in imgList:\n",
    "\n",
    "        try :\n",
    "\n",
    "            params.append(im[\"src\"])                   # params 리스트에 image url 을 담음.\n",
    "\n",
    "        except KeyError:                                  # 이미지의 상세 url 의 값이 있는 src 가 없을 경우\n",
    "\n",
    "            params.append(im[\"data-src\"])            # 이미지의 상세 url 의 값이 있는 src 가 없을 경우 data-src 로 가져오게\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "def fetch_detail_url():\n",
    "\n",
    "    params = fetch_list_url()\n",
    "\n",
    "    for idx,p in enumerate(params,1):    # enumerate 는 리스트의 모든 요소를 인덱스와 쌍으로 추출\n",
    "\n",
    "        urllib.request.urlretrieve(p, \"C:/gimages2/\" + str(idx) + \"_google.jpg\")    # 다운받을 폴더경로 입력\n",
    "\n",
    "\n",
    "\n",
    "fetch_detail_url()\n",
    "\n",
    "\n",
    "\n",
    "browser.quit()    # 끝나면 브라우져 닫기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
